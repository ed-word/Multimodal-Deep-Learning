{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialise config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install --upgrade tensorflow_hub\n",
    "!pip install --upgrade pydot\n",
    "!pip install --upgrade graphviz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow.keras as keras\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "\n",
    "#HYPERPARAMETERS\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=20\n",
    "\n",
    "new_shape = (150,150)\n",
    "\n",
    "\n",
    "max_words = 15\n",
    "\n",
    "\n",
    "\n",
    "labels_dict = {\n",
    "    0: 'missing',\n",
    "    1: 'not-easy-fraud',\n",
    "    2: 'replaced'\n",
    "}\n",
    "\n",
    "rev_labels_dict = {\n",
    "    'missing': 0,\n",
    "    'not-easy-fraud': 1,\n",
    "    'replaced': 2\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "Need to revise these values after imbalanced augmentation\n",
    "'''\n",
    "num_records = {\n",
    "    'missing': 1000,\n",
    "    'not-easy-fraud': 30000,\n",
    "    'replaced': 350\n",
    "}\n",
    "\n",
    "num_augmentations = {\n",
    "    'missing': 5,\n",
    "    'not-easy-fraud': 3,\n",
    "    'replaced': 10\n",
    "}\n",
    "\n",
    "num_records_after_augmentation = {\n",
    "    'missing': num_records['missing']*num_augmentations['missing'],\n",
    "    'not-easy-fraud': num_records['not-easy-fraud']*num_augmentations['not-easy-fraud'],\n",
    "    'replaced': num_records['replaced']*num_augmentations['replaced']\n",
    "}\n",
    "\n",
    "# Majority class (not fraud)\n",
    "records = num_records_after_augmentation['not-easy-fraud']\n",
    "total_records = sum([num_records_after_augmentation[key] for key in num_records_after_augmentation])\n",
    "missing_records = num_records_after_augmentation['missing']\n",
    "replaced_records = num_records_after_augmentation['replaced']\n",
    "\n",
    "print(records)\n",
    "print(total_records)\n",
    "print(num_records_after_augmentation['missing'])\n",
    "print(num_records_after_augmentation['replaced'])\n",
    "\n",
    "class_weight = {\n",
    "    0: records/missing_records,\n",
    "    1: 1,\n",
    "    2: records/replaced_records\n",
    "}\n",
    "print(class_weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading and Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the files\n",
    "<a id='cell:data_description'></a>\n",
    "Please download the data from the following [WorkDocs link](https://amazon.awsapps.com/workdocs/index.html#/folder/4aefea54a65e7377cd884e1a54f341dc62aec676d88ac31127f4d88e75d63f28). It includes the following files:\n",
    "- images.part_aa\n",
    "- images.part_ab\n",
    "- images.part_ac\n",
    "- images.part_ad\n",
    "- train_data.csv\n",
    "- test_features.csv\n",
    "\n",
    "The first 4 files are part files which when concatenated lead to a tar ball containing the image files. The `train_data.csv` contains the training data, while the `test_features.csv` contains the test data (used for both the Public and Private Leaderboard) and thus **does not** include the labels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download google universal encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#download the model to local so it can be used again and again\n",
    "# !mkdir universalencoder\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "# !curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC universalencoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's see what kind of data we're dealing with\n",
    "train_data = pd.read_csv('WW Returns/train_data.csv')\n",
    "train_data.tail(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the images\n",
    "The images are present in a tar file which has been split into part files for making the download/upload convenient. First make sure that you have all the 4 files mentioned [here](#cell:data_description). Run the following cell to stitch the part files together and get the images."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's try to look at an image for a return!\n",
    "%pylab inline\n",
    "\n",
    "index = -3\n",
    "image_id, label = train_data.iloc[index]['image_id'], train_data.iloc[index]['label']\n",
    "image_path = os.path.join('WW Returns/images', image_id)\n",
    "image = mpimg.imread(image_path)\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Label: {}\".format(label), fontsize=16)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "- Get sample batch and fit it on ImageDataGenerator for zca\n",
    "- Define train and validation set from pandas dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "def preprocessing_fun(image):\n",
    "    img = np.array(image)\n",
    "    img /= 127.5\n",
    "    img -= 1\n",
    "    return img\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "#     zca_whitening=True,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    preprocessing_function = preprocessing_fun, \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.2,1.0],\n",
    "    fill_mode='nearest')\n",
    "\n",
    "\n",
    "# Need to fit this since zca_whitening is used\n",
    "# train_sample = datagen.flow_from_dataframe(dataframe=train_data[0:5], \n",
    "#                                               directory='WW Returns/images/',\n",
    "#                                               x_col=\"image_id\", \n",
    "#                                               y_col=\"label\", \n",
    "#                                               class_mode=\"categorical\",\n",
    "#                                                 classes=['missing', 'not-easy-fraud', 'replaced'],\n",
    "#                                               target_size=(150, 150), \n",
    "#                                         color_mode='rgb',\n",
    "#                                               batch_size=5)\n",
    "# for batch in train_sample:\n",
    "#     datagen.fit(batch[0])\n",
    "#     break\n",
    "    \n",
    "    \n",
    "\n",
    "with open('datagen.pb', 'wb') as datagen_file:\n",
    "    pickle.dump(datagen, datagen_file)\n",
    "    \n",
    "\n",
    "with open('datagen.pb', 'rb') as datagen_file:\n",
    "    datagen = pickle.load(datagen_file)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# There will be 3 text inputs\n",
    "# 1. gl_product: Here we will split by ('_') and remove numbers eg. gl_product_9_digital and remove the first 'gl'\n",
    "# 2. cat_desc: Here - \"1000 Point_&_Shoot\", \"1400 Health & Wellness (121)\" we will remove number and & and (121) and _ and /\n",
    "# 3. subcat_desc: Same as above and DELETED and remove any word that contains numbers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "\n",
    "def split(string):\n",
    "    delimiters = \",\", \"_\", \"/\", \"&\", \" \"\n",
    "    regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "    return re.split(regexPattern, string)\n",
    "\n",
    "def remove(strList):\n",
    "    # Given list of words, remove/edit some words eg. (121)\n",
    "    # Remove words that contain numbers\n",
    "    # Remove DELETED\n",
    "    # Remove gl\n",
    "    return [i.lower() for i in strList if i.isalpha() and i != 'DELETED' and i != 'gl']\n",
    "\n",
    "def embedWords(listString):\n",
    "    # Either pass one word: \"Computer\" or sentence \"I am a computer\"\n",
    "    return embed(listString)\n",
    "\n",
    "\n",
    "\n",
    "def process_text(row):\n",
    "    gl = row['gl_product_group_desc']\n",
    "    cat = row['cat_desc']\n",
    "    subcat = row['subcat_desc']\n",
    "    \n",
    "#     print(\"GL: \" + gl)\n",
    "    splitGl = split(gl)\n",
    "    finalGl = remove(splitGl)\n",
    "#     print(\"SplitGL: \" + str(splitGl))\n",
    "#     print(\"FinalGL: \" + finalGl)\n",
    "#     print()\n",
    "    \n",
    "#     print(\"Cat: \" + cat)\n",
    "    splitCat = split(cat)\n",
    "    finalCat = remove(splitCat)\n",
    "#     print(\"SpCat: \" + str(splitCat))\n",
    "#     print(\"FCat: \" + finalCat)\n",
    "#     print()\n",
    "    \n",
    "#     print(\"SubCat: \" + subcat)\n",
    "    splitSubcat = split(subcat)\n",
    "    finalSubcat = remove(splitSubcat)\n",
    "#     print(\"Split SubCat: \" + str(splitSubcat))\n",
    "#     print(\"FSubCat: \" + finalSubcat)\n",
    "#     print()\n",
    "    \n",
    "#     print(\"--------------------\\n\")\n",
    "    words = [i for i in finalGl+finalCat+finalSubcat]\n",
    "    return embedWords(words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shuffle data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Generators: Option 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_gen = datagen.flow_from_dataframe(dataframe=train_data[:-1000], \n",
    "                                              directory='WW Returns/images/',\n",
    "                                              x_col=\"image_id\", \n",
    "                                              y_col=\"label\", \n",
    "                                              class_mode=\"categorical\",\n",
    "                                                classes=['missing', 'not-easy-fraud', 'replaced'],\n",
    "                                              target_size=(150, 150), \n",
    "                                        color_mode='rgb',\n",
    "                                              batch_size=256)\n",
    "# Classes are encoded in 1 hot vector by alphabetical order\n",
    "\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(dataframe=train_data[-1000:], \n",
    "                                              directory='WW Returns/images/',\n",
    "                                              x_col=\"image_id\", \n",
    "                                              y_col=\"label\", \n",
    "                                              class_mode=\"categorical\",\n",
    "                                                classes=['missing', 'not-easy-fraud', 'replaced'],\n",
    "                                              target_size=(150, 150), \n",
    "                                      color_mode='rgb',\n",
    "                                              batch_size=256)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Generators: Option 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, dataframe, batch_size=32):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.dataframe = dataframe\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        # indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of IDs\n",
    "        dataframe_batch = self.dataframe[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(dataframe_batch)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.dataframe))\n",
    "\n",
    "    def __data_generation(self, dataframe_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "    \n",
    "        X_images = []\n",
    "        X_text = []\n",
    "        Y = []\n",
    "        for index, data in dataframe_batch.iterrows():\n",
    "            label = data['label']\n",
    "            y = rev_labels_dict[label]\n",
    "            image_id = data['image_id']\n",
    "            \n",
    "            x_text = process_text(data)\n",
    "            x_text_padded = np.zeros((max_words, 512))\n",
    "            x_text_padded[:x_text.shape[0],:x_text.shape[1]] = x_text\n",
    "\n",
    "            image_path = os.path.join('WW Returns', 'images', image_id)\n",
    "            image = cv2.imread(image_path).astype(np.float32)\n",
    "\n",
    "            image = cv2.resize(image, new_shape)\n",
    "            preprocessed_image = preprocessing_fun(image)\n",
    "            X_images.append(preprocessed_image)\n",
    "            X_images.append(preprocessed_image)\n",
    "            Y.append(y)\n",
    "            Y.append(y)\n",
    "            X_text.append(x_text_padded)\n",
    "            X_text.append(x_text_padded)\n",
    "            \n",
    "            \n",
    "\n",
    "            num_of_aug = 1\n",
    "            MAX_NUM_OF_AUG = num_augmentations[label] - 2\n",
    "            for batch in datagen.flow(np.expand_dims(image, axis=0)):\n",
    "                aug_image = batch[0]\n",
    "\n",
    "                X_images.append(aug_image)\n",
    "                Y.append(y)\n",
    "                X_text.append(x_text_padded)\n",
    "\n",
    "                if num_of_aug >= MAX_NUM_OF_AUG:\n",
    "                    break\n",
    "                num_of_aug = num_of_aug+1\n",
    "\n",
    "                \n",
    "        return [np.array(X_images), np.array(X_text)], keras.utils.to_categorical(Y, num_classes=3)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "image_input = keras.Input(shape=(150, 150, 3), name='image_input')\n",
    "\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "base_cnn_with_input = base_model(image_input, training=False)\n",
    "cnn_gavg = keras.layers.GlobalAveragePooling2D()(base_cnn_with_input)\n",
    "cnn_drop = keras.layers.Dropout(0.2)(cnn_gavg)  # Regularize with dropout\n",
    "cnn_dense_32 = keras.layers.Dense(32, activation='relu')(cnn_drop)\n",
    "cnn_dense_16 = keras.layers.Dense(16, activation='relu')(cnn_dense_32)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "word_embeddings = keras.Input(shape=(max_words,512), name='word_embeddings')\n",
    "encoded_tag = keras.layers.LSTM(64)(word_embeddings)\n",
    "x_text_layer = keras.layers.Dense(32, activation='relu')(encoded_tag)\n",
    "x_text_layer = keras.layers.Dense(16, activation='relu')(x_text_layer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "concatenated = keras.layers.concatenate([cnn_dense_16, x_text_layer], axis=-1)\n",
    "concatenated = keras.layers.Dense(16, activation='relu')(concatenated)\n",
    "\n",
    "outputs = keras.layers.Dense(3, activation='softmax')(concatenated)\n",
    "model = keras.Model([image_input, word_embeddings] , outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Evaluate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save JSON config to disk\n",
    "\n",
    "def save_model(iteration=None, model=model):\n",
    "    json_config = model.to_json()\n",
    "    with open('model_config.json', 'w') as json_file:\n",
    "        json_file.write(json_config)\n",
    "    # Save weights to disk\n",
    "    \n",
    "    if iteration:\n",
    "        file_path = 'path_to_my_weights_' + iteration + '.h5'\n",
    "    else:\n",
    "        file_path = 'path_to_my_weights.h5'\n",
    "    file1 = open(file_path,\"w\")\n",
    "    file1.close()\n",
    "    \n",
    "    model.save_weights(\"path_to_my_weights.h5\")\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_model():\n",
    "    # Reload the model from the 2 files we saved\n",
    "    with open('model_config.json') as json_file:\n",
    "        json_config = json_file.read()\n",
    "    new_model = keras.models.model_from_json(json_config)\n",
    "    file_path = 'path_to_my_weights.h5'\n",
    "    new_model.load_weights(file_path)\n",
    "    return new_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#%%capture test\n",
    "\n",
    "def test_full(model):\n",
    "    \n",
    "    import string\n",
    "    import random\n",
    "\n",
    "    # initializing size of string \n",
    "    N = 7\n",
    "    # using random.choices()\n",
    "    # generating random strings \n",
    "    res = ''.join(random.choices(string.ascii_uppercase +\n",
    "                                 string.digits, k = N))\n",
    "    file_path = 'predictions_' + res + '.csv'\n",
    "    \n",
    "    # Let's look at the test data we need to make predictions for\n",
    "    test_features = pd.read_csv('WW Returns/test_features.csv')\n",
    "    test_features.head()\n",
    "\n",
    "    # Below is an example submission of a baseline model with directions on how to submit to Leaderboard\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df['ID'] = test_features['ID']\n",
    "\n",
    "    result_df = pd.read_csv('Results/predictions.csv')\n",
    "    result_df['ID'] = test_features['ID']\n",
    "    result_df['label'] = ''\n",
    "\n",
    "\n",
    "\n",
    "    NUM_OF_TEST_AUGMENTATIONS = 10\n",
    "\n",
    "    for index, data in test_features.iterrows():\n",
    "        if (result_df.at[index,'label'] != ''):\n",
    "            continue\n",
    "\n",
    "        image_id = data['image_id']\n",
    "        test_id = data['ID']\n",
    "\n",
    "        print(\"Index: \" + str(index))\n",
    "        print(\"Image_id: \" + str(image_id))\n",
    "        print(\"ID: \" + str(test_id))\n",
    "        \n",
    "        \n",
    "        x_text = process_text(data)\n",
    "        x_text_padded = np.zeros((max_words, 512))\n",
    "        x_text_padded[:x_text.shape[0],:x_text.shape[1]] = x_text\n",
    "\n",
    "\n",
    "        image_path = os.path.join('WW Returns', 'images', image_id)\n",
    "        image = cv2.imread(image_path).astype(np.float32)\n",
    "        image = cv2.resize(image, new_shape)\n",
    "\n",
    "        preprocessed_image = preprocessing_fun(image)\n",
    "        img_arr = [preprocessed_image, preprocessed_image, preprocessed_image]\n",
    "        txt_arr = [x_text_padded, x_text_padded, x_text_padded]\n",
    "\n",
    "        num = 1\n",
    "        for batch in datagen.flow(np.expand_dims(image, axis=0)):\n",
    "            img_arr.append(batch[0])\n",
    "            txt_arr.append(x_text_padded)\n",
    "\n",
    "            if num >= NUM_OF_TEST_AUGMENTATIONS:\n",
    "                break\n",
    "            num = num+1\n",
    "\n",
    "        img_arr = np.array(img_arr)\n",
    "        txt_arr = np.array(txt_arr)\n",
    "        predictions = model.predict([img_arr, txt_arr])\n",
    "\n",
    "        predictions = np.sum(predictions, axis=0)\n",
    "        print(predictions)\n",
    "\n",
    "        label = labels_dict[np.argmax(predictions)]\n",
    "        print(label)\n",
    "        result_df.at[index,'label']=label\n",
    "        print(\"\\n\\n\")\n",
    "        result_df.to_csv(os.path.join('Results', file_path), index = False)\n",
    "        clear_output(wait=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %%capture train\n",
    "BATCH_SIZE=400\n",
    "\n",
    "# Generators\n",
    "train_gen = DataGenerator(train_data[:-1000], batch_size=BATCH_SIZE)\n",
    "val_gen = DataGenerator(train_data[-1000:], batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "def fine_tune(model):\n",
    "    history = model.fit(val_gen, epochs=2, validation_data=val_gen, class_weight=class_weight)\n",
    "    # Fine tuning\n",
    "    # Unfreeze the base model\n",
    "    base_model.trainable = True\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(train_gen, epochs=2, validation_data=val_gen, class_weight=class_weight)\n",
    "    base_model.trainable = False\n",
    "    return model\n",
    "\n",
    "def train(model, resume=False):\n",
    "    if resume:\n",
    "        model = load_model()\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        model = fine_tune(model=model)\n",
    "        test_full(model=model)\n",
    "        model = load_model()\n",
    "        \n",
    "    for i in range(10):\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        history = model.fit(train_gen, epochs=5, validation_data=val_gen, class_weight=class_weight)\n",
    "        model = save_model(iteration=str(i), model=model)\n",
    "        \n",
    "        model = fine_tune(model=model)\n",
    "        test_full(model=model)\n",
    "        model = load_model()\n",
    "\n",
    "    loss, acc = model.evaluate(val_gen)  # returns loss and metrics\n",
    "    print(\"loss: %.2f\" % loss)\n",
    "    print(\"acc: %.2f\" % acc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train(model, True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}